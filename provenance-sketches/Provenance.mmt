namespace http://www.opendreamkit.org/ ❚

/T We provide a first infrastructure for formalized provenance of mathematical data. The
  idea behind this is that mathematical data sets are (usually) generated computationally,
  possibly using existing data sets as input.

  We model provenance as MMT terms that describe concrete computations, i.e. the
  application of a concrete implementation to a set of existing data sets and parameters.

  Implementation objects are concrete realizations of algorithms, which we (for now) leave
  atomic.

  For concrete examples see the theory $?Examples$ below.

  For use in the MathDataHub System (see http://mdhalpa.mathhub.info) we expecte a
  form-based interface which provides a check-list, the data set author can fill out and
  which generates well-typed provenance terms. 
❚

theory Meta : mitm:/Foundation?Logic =
    include ☞mitm:/Foundation?Lists ❙
    include ☞mitm:/Foundation?Strings ❙
❚

theory Provenance : ?Meta =

    /T we leave algorithms atomic for now. ❙
    algorithm : type ❙
    /T we leave algorithms atomic here. They are identified by (and constructed from) a
       URI in the MathDataHub system, e.g. https://mdhalpha.mathhub.info/collection/ab/ ❙
    dataset : type ❙
    ds : string ⟶ dataset ❙

    /T Implementation objects are concrete realizations of algorithms. We also record what
      libraries are used, where the code is available (a list of URIs), licenses and
      programming language. ❙

    theory implementation_theory : ?Meta > A : algorithm ❘ =
        uses_libs : List string ❙
        available_at : List string ❙
	main: string❙
        revision : List string ❙
        license : List string ❙
        language : List string ❙
    ❚
    implementation : algorithm ⟶ type ❘ = [A:algorithm] Mod ☞?Provenance/implementation_theory A ❙

    /T Computation objects model computational events that apply a concrete implementation to a
       set of existing data sets and parameters. We also record various metadata-like
       properties of the computation event. ❙
       
    theory computation_theory > A : algorithm, I : implementation A ❘ =
        start_time : List string ❙
        machine : List string ❙
        runtime : List string ❙
        memory_usage : List string ❙
        who_ran_it : List string ❙
        parameters : List string ❙
        inputs : List dataset ❙
    ❚
    computation : {A} implementation A ⟶ type ❘ = [A:algorithm,I: implementation A] Mod ☞?Provenance/computation_theory A I ❘ # computation 2 ❙

    /T A provenance theory ties algorithms, implementations, and computations together
       with the data set that creates. ❙
    theory provenance_theory > DS : dataset ❘ =
        algo : algorithm ❙
        impl : implementation algo ❙
        comp : computation impl ❙
    ❚
    provenance : dataset ⟶ type ❘ = [DS] Mod ☞?Provenance/provenance_theory DS ❙
    /T  In practice we use the $?from_comp$ constructor to write down provenance given a
       computation object. ❙
    producedBy : {DS:dataset, A : algorithm, I : implementation A} computation I ⟶ provenance DS ❘ # producedBy 1 4 ❙

    /T We supply a common "computational object", which models the common practice to
       massage a data set into a form a script or implementation can process by manually applying
       regular expression replacement e.g. in an editor until the syntax matches the input
       format of the implementation.  ❙
    regexp_massage:algorithm ❙
    via_regexp : implementation regexp_massage ❘ = ['
        uses_libs := nil ,
        available_at := nil ,
        license := nil ,
        language := ls "with regexp"
    '] ❙
❚

/T To fortify our intuition, let us look at an extended exapmle. ❙
theory Quicksorting_Numbers_and_postprocessing : ?Provenance =

    /T We start with an input data set  ❙ 
    ds1 : dataset ❘ = ds "3-digit numbers randomly ordered" ❙

    /T Quicksort is an algorithm, which we assume as a given. ❙ 
    quicksort:algorithm ❙

    /T Quicksort has a java implementation which is available on Github, we have used a
    particular revision ❙ 
    qs4j : implementation quicksort ❘ = ['
        uses_libs := (ls "scala_lib","scalaxml"),
        available_at := (ls "https://github.com/example/qs4j/"),
	revision := (ls "d4adbf7b81750b492708aba4d102810cf0646029")
        license := (ls "GPL3"),
        language := (ls "Java")
    '] ❙

    /T and now a computation based on this implementation. ❙
    comp : computation qs4j ❘ = ['
        start_time := (ls "23 BCE") ,
        machine := (ls "my laptop") ,
        runtime := (ls "way too long") ,
        memory_usage := (ls "42b") ,
        who_ran_it := (ls "Julius Cesar"),
        parameters := (ls "--help" , "me"),
        inputs := (ls ds1)
    '] ❙

    /T The result of this computation is an alphabetically sorted data set. ❙
    d_s : dataset ❘ = ds "3-digit numbers sorted alphabetically" ❙

    /T We tie the provenance to the computation above.   ❙
    provd_s : producedBy d_s comp ❙
   
   /T As a final step,  we massage the list into PERL format, we model this by a
      "computation event", which uses the ready-made ready-mande "implementation"
      $provenance?via_regexp$ and record the metadata ❙   
   proc_perl :  computation via_regexp ❘ = ['
        start_time := (ls "2019-05-07") ,
        machine := (ls "my laptop") ,
        runtime := (ls "negligible") ,
        memory_usage := nil ,
        who_ran_it := (ls "Hans Dampf") ,
        parameters := nil ,
        input := d_s
    '] ❙

    /T the result of the computation in $?proc_perl$ is the final data set. ❙
    d_s_processed : dataset ❘ = ds "3-digit numbers sorted alphabetically processed for PERL" ❙
   processed : prov d_s_processed proc_perl ❙
❚

/T To fortify our intuition, let us look at an extended exapmle. ❙
theory Fibonacci : ?Provenance =

    /T We use the naive recursion algorithm for generating fibonacci numbers. ❙ 
    fib_naive_recursion:algorithm ❙

    /T We use a fake implementation for this example.❙ 
    myImpl : implementation fib_naive_recursion ❘ = ['
        uses_libs := (ls "numpy"),
        available_at := (ls "https://mydomain.com/fibonacci/"),
	main := ("naive.py"),
	revision := (ls "1.0")
        license := (ls "GPL3"),
        language := (ls "Python")
    '] ❙

    /T and now a computation based on this implementation. ❙
    comp : computation myImpl ❘ = ['
        start_time := (ls "23 BCE") ,
        machine := (ls "my laptop") ,
        runtime := (ls "way too long") ,
        memory_usage := (ls "42b") ,
        who_ran_it := (ls "Julius Cesar"),
        parameters := (ls "-upto" , "10"),
        inputs := (nil)
    '] ❙

    /T an identifier for the resulting dataset❙
    myFibTable: dataset❙

    /T We tie the dataset to the computation.   ❙
    provenance : producedBy myFibTable comp ❙
❚



theory Kohonen_2018_lattices : ?Provenance =

    /T The algorithm is described in <https://doi.org/10.1007/s11083-018-9475-2>. I don't know where you want this pointer. ❙ 
    KohonenLatticeAlgo: algorithm ❙

    gralist : implementation KohonenLatticeAlgo❘ = ['
        uses_libs := (ls "nauty 2.6r11"),
        available_at := (ls "https://b2share.eudat.eu/records/dbb096da4e364b5e9e37b982431f41de/"),
	main := ("gralist.c"),
	revision := (nil)
        license := (ls "MIT"),
        language := (ls "C")
    '] ❙

    /T Kohonen actually runs the algorithm separately for each size, i.e., he produces a separate dataset per size. For simplicity, in this example, for each lattice type we describe the biggest size only.❙
    modular2016 : computation gralist❘ = ['
        start_time := (ls "January 2016") ,
        machine := (ls "taito.csc.fi / single 2.6 GHz Intel Xeon E5-2690 core") ,
        runtime := (ls "79661.32 s") ,
        memory_usage := (ls "Some GB") ,
        who_ran_it := (ls "Jukka Kohonen"),
        parameters := (ls "-slmi", "30"),
        inputs := (nil)
    '] ❙

    graded2016 : computation gralist❘ = ['
        start_time := (ls "January 2016") ,
        machine := (ls "taito.csc.fi / single 2.6 GHz Intel Xeon E5-2690 core") ,
        runtime := (ls "142496.2 s") ,
        memory_usage := (ls "Some GB") ,
        who_ran_it := (ls "Jukka Kohonen"),
        parameters := (ls "-mi", "21"),
        inputs := (nil)
    '] ❙

    semimodular2016 : computation gralist❘ = ['
        start_time := (ls "January 2016") ,
        machine := (ls "taito.csc.fi / single 2.6 GHz Intel Xeon E5-2690 core") ,
        runtime := (ls "37775.25 s") ,
        memory_usage := (ls "Some GB") ,
        who_ran_it := (ls "Jukka Kohonen"),
        parameters := (ls "-lmi", "25"),
        inputs := (nil)
    '] ❙

    geometric2016 : computation gralist❘ = ['
        start_time := (ls "January 2016") ,
        machine := (ls "taito.csc.fi / single 2.6 GHz Intel Xeon E5-2690 core") ,
        runtime := (ls "1203.81 s") ,
        memory_usage := (ls "Some GB") ,
        who_ran_it := (ls "Jukka Kohonen"),
        parameters := (ls "-lcmi", "34"),
        inputs := (nil)
    '] ❙

    /T The datasets were produced by the computations.   ❙

    modularLattices30: dataset❙
    provenance : producedBy modularLattices30 modular2016 ❙

    gradedLattices21: dataset❙
    provenance : producedBy gradedLattices21 graded2016 ❙

    semimodularLattices25: dataset❙
    provenance : producedBy semimodularLattices25 semimodular2016 ❙

    geometricLattices34: dataset❙
    provenance : producedBy geometricLattices21 geometric2016 ❙



❚
